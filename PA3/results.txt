2.1)
evaluation	Results sparse	Results dense
single	0.91	0.53
cval_1	0.44	0.0
cval_2	0.22	0.0
cval_3	0.67	0.67
cval_4	0.78	1.0
cval_5	0.78	1.0
cval_AVG	0.58	0.53

2.2) Decisions for both methods:
window size: 5
preprocessing: In all files (text, T, B): lowercase, remove punctuation, trivial tokenization in words by space (using split()).

2.3) Comparision
Method single evaluation has higher accuracy scores, since classifier has seen all data and was optimized on them. No surprises for the classifier. Could in theory, if the points are seperable, have accuracy of 100% by learning a perfect seperation line. In practice such a seperation is probabely not possible, but classifier could learn all examples -> still 100% accurate. But since a classifier needs to predict unseen, unlabeled words this evaluation is useless. On the other hand the method cross validation is much more realistic, the classifier is tested on unseen data and hence can not optimize on the test set or learn it 'by heart'. Accuracy scores are lower and depending on the data used for testing, can be very low (sparse results on fold two) -> set contains special cases/unrepresentative examples. When comparing the accuracy of the classifier using different word embedding methods: accuracy using dense representations (word2vec) are more useful for the classifier to adapt to. Word embeddings seem to be generated with a certain inner logic, hence word-vectors of war and peace seem to be more different/each category lies in a different space (maybe even form something cluster-like. This can be easily seperated by our classifier (hence average accuracy (cval_AVG) on dense vectors is notably higher than on sparse vectors. Word2Vec was not able with the settings (esp. window size 5) to generate an embedding for birthday, extending window size could help. 
